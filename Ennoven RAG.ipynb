{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f8a93-6bb4-4146-bc5b-99d8aee8c2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dependencias\n",
    "!pip install pypdf langchain langchain-community langchain-core langchain-openai chromadb python-dotenv\n",
    "\n",
    "# Usar solo en Databricks\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee64ef-1c0d-491a-a8be-2df4028a4179",
   "metadata": {},
   "source": [
    "# Ejercicio de Ingeniería de Software con Inteligencia Artificial\n",
    "\n",
    "## Descripción de la Prueba\n",
    "\n",
    "El objetivo de esta prueba es evaluar tus habilidades y conocimientos en el desarrollo de software con inteligencia artificial, específicamente en sistemas RAG (Retrieval-Augmented Generation), embeddings, y bases de datos vectoriales.\n",
    "\n",
    "Se te proporcionarán tres archivos PDF con reportes de resultados de Grupo Bimbo, así como las llaves de API y los endpoints de OpenAI. Tu tarea será utilizar estos recursos para desarrollar un sistema que pueda realizar tareas de retrieval de manera eficiente.\n",
    "\n",
    "## Objetivos de la Prueba\n",
    "\n",
    "1. Comprensión de los datos: Deberás ser capaz de procesar y entender los datos proporcionados en los archivos PDF.\n",
    "\n",
    "2. Uso de OpenAI y embeddings: Deberás demostrar tu habilidad para trabajar con OpenAI y embeddings para realizar tareas de retrieval.\n",
    "\n",
    "3. Implementación de bases de datos vectoriales: Deberás implementar una base de datos vectorial para manejar eficientemente los datos.\n",
    "\n",
    "4. Desarrollo de un sistema RAG: Finalmente, deberás demostrar tu capacidad para desarrollar un sistema RAG que pueda realizar tareas de retrieval y generación de texto de manera eficiente.\n",
    "\n",
    "## Presentación del Código\n",
    "\n",
    "Tu código debe seguir las mejores prácticas de codificación y puede presentarse en notebooks de Jupyter. Esto incluye:\n",
    "\n",
    "· Legibilidad: El código debe ser fácil de leer y entender.\n",
    "\n",
    "· Comentarios: Debes incluir comentarios que expliquen tu razonamiento y las decisiones de diseño que tomaste.\n",
    "\n",
    "· Estructura: El código debe estar bien estructurado y organizado.\n",
    "\n",
    "· Pruebas: Debes incluir pruebas para asegurar que tu código funciona como se espera.\n",
    "\n",
    "Para revisión de este proyecto ser realizará una sesión en línea donde presentarás tu abordaje el problema, tu resolución técnica y código generado.\n",
    "\n",
    "- APIkey: 75433f0e2ce040ebb90a2fa457fbc815\n",
    "- EndPoint: https://ennovenoai.openai.azure.com/\n",
    "- Modelo Openai: EnnovenGPTTurbo\n",
    "- Modelo Ada-002: EnnovenAda\n",
    "\n",
    "Anexo igualmente los PDFs que sirven como fuente de datos para el sistema RAG, recordando que buscamos una búsqueda enriquecida: (Datos + metadata)\n",
    "\n",
    "El archivo contiene tablas, e imágenes, así como textos. Se espera del ejercicio el procesamiento de las tablas e imágenes dentro del modelo. Así como una aproximación de reranking de los resultados para un mejor contexto de respuesta.\n",
    "\n",
    "Las API Keys serán cambiadas una ves terminado el ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19588d92-68d9-47b0-a4c4-7c5860165125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bibliotecas para interactuar con el LLM\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "# Para generar los embeddings\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# Para cargar los datos en formato PDF\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# Para el splitting de los textos\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Para almacenar los embeddings en ChromaDB\n",
    "from langchain_community.vectorstores import Chroma\n",
    "# Para generar el RAG usando la base de datos vectorial\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "# Para crear un template y obtener respuestas personalizadas\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# Interactuar con el sistema de archivos\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar las variables de ambiente desde el .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6f941-767f-4ced-af2d-2a10da1d9642",
   "metadata": {},
   "source": [
    "## Credenciales de accesso\n",
    "\n",
    "Para Databricks: Las credenciales de acceso al modelo han sido almacenadas en variables de ambiente en la configuración del Clúster para mayor seguridad.\n",
    "\n",
    "<img src=\"./img/databricks-env-variables.png\">\n",
    "\n",
    "Para entornos de prueba local: Las credenciales se encuentran en un archivo `.env`\n",
    "\n",
    "<img src=\"./img/variables-de-ambiente.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311ce685-4ec3-4c1f-bf52-e1b4e35d3776",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_version = os.environ[\"OPENAI_API_VERSION\"]\n",
    "azure_deployment = os.environ[\"AZURE_DEPLOYMENT\"]\n",
    "azure_openai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "model_name = os.environ[\"MODEL_NAME\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a26845-ecbe-4319-8c40-b48b095bd253",
   "metadata": {},
   "source": [
    "Creamos una instancia para usar el modelo de ChatGPT de Azure y el modelo para generar los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7f7c2d-986a-4656-ab87-bf85f124c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una conexión con el modelo GPT de Azure\n",
    "model = AzureChatOpenAI(\n",
    "    api_key = azure_openai_api_key, # API Key\n",
    "    azure_endpoint = azure_openai_endpoint, # Endpoint\n",
    "    openai_api_version = openai_api_version, # Obtenido de la documentación\n",
    "    model_name = model_name, # Nombre del modelo\n",
    "    temperature = 0 # Temperatura del modelo GPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "739c7577-6aae-4e13-bd18-1f07aa89f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo para generar los embeddings\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    api_key = azure_openai_api_key, # API Key\n",
    "    azure_endpoint = azure_openai_endpoint, # Endpoint\n",
    "    azure_deployment = azure_deployment, # Nombre del modelo de embeddings\n",
    "    openai_api_version = openai_api_version # Obtenido de la documentación\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "898e5933",
   "metadata": {},
   "source": [
    "# Hiperparametros para el splitting\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 200\n",
    "\n",
    "# Inicializar el splitter con los hiperparametros\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size, \n",
    "    chunk_overlap = chunk_overlap,\n",
    "    separators = [\".\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44e45e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splitter(chunk_size : int, chunk_overlap : int, separators : list | None = None) -> RecursiveCharacterTextSplitter:\n",
    "    \"\"\"\n",
    "    Función que permite instanciar un objeto para splitting de caracteres recursivamente\n",
    "    \"\"\"\n",
    "    # Inicializar el splitter con los hiperparametros\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size, \n",
    "        chunk_overlap = chunk_overlap,\n",
    "        separators = separators\n",
    "    )\n",
    "\n",
    "    return splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0ae4359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database(directory : str, model = AzureOpenAIEmbeddings, collection = str) -> Chroma:\n",
    "    \"\"\"\n",
    "    Función que permite crear una base de datos vectorial usando ChromaDB\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializar la base de datos vectorial\n",
    "    vectordb = Chroma(\n",
    "        persist_directory = directory,\n",
    "        embedding_function = model,\n",
    "        collection_name = collection\n",
    "    )\n",
    "\n",
    "    # Configurar Chroma para hacer datos persistentes en disco\n",
    "    vectordb.persist()\n",
    "    \n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e31b0b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.text_splitter.RecursiveCharacterTextSplitter at 0x7fef393495a0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciar el splitter de texto\n",
    "splitter = get_splitter(chunk_size = 1000, chunk_overlap = 200, separators = [\".\"])\n",
    "splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3a14a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x7fef3a2b1e70>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciar una conexión con la base de datos vectorial\n",
    "vectordb = get_database(directory = \"db\", model = embedding_model, collection = \"ennoven_db\")\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211004b9",
   "metadata": {},
   "source": [
    "A continuación, se muestra un ciclo de trabajo en el que se leen los archivos PDF que se encuentran en el directorio `data` y se procesan uno por uno.\n",
    "\n",
    "Las tres etapas se definen a continuación:\n",
    "\n",
    "## Etapa 1: Ingesta de datos (usando Loaders)\n",
    "\n",
    "Dependiendo del caso de uso, pueden existir multiples tipos de formatos de archivos que quisiera llegar a procesarse.\n",
    "\n",
    "LangChain ofrece una extensa variedad de Loaders que permiten cargar estos datos que pueden consultarse aquí: https://python.langchain.com/docs/integrations/document_loaders\n",
    "\n",
    "En este caso, estamos usando un loader especial para cargar archivos PDF.\n",
    "\n",
    "## Etapa 2: Separación de los textos por lotes (chunks)\n",
    "\n",
    "Separar los textos permite obtener porciones fáciles de procesar y utilizar por el modelo de IA para ofrecer un contexto por similitud. Este proceso involucra establecer una logitud de caracteres y una unión de información entre estos (overlap).\n",
    "\n",
    "Los parametros que permiten realizar esto son `chunk_size` y `chunk_overlap` respectivamente. \n",
    "\n",
    "Para la separación de los textos, se está usando `RecursiveCharacterTextSplitter`.\n",
    "\n",
    "## Etapa 3: Crear representaciones vectoriales de los chunks \n",
    "\n",
    "Las representaciones vectoriales permite convertir texto en vectores numericos que permiten mantener el contexto, semantica y similitud entre los chunks de textos que separamos anteriormente. \n",
    "\n",
    "Para generar los embeddings, tenemos que usar un modelo especialmente para esto, en este caso, estamos usando `EnnovenAda`, aunque existen muchos otros que pueden encontrarse tanto en OpenAI (embeddings propietario) como en TheHuggingFace\n",
    "\n",
    "<img src=\"./img/embedding-models.png\" width = \"1200px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3996665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/Reporte_Definitivo_BMV_XBRL_Español_Mar_23.pdf\n",
      "Extracting text from file: data/Reporte_Definitivo_BMV_XBRL_Español_Mar_23.pdf\n",
      "Splitting docs for data/Reporte_Definitivo_BMV_XBRL_Español_Mar_23.pdf\n",
      "Creating embeddings for docs in data/Reporte_Definitivo_BMV_XBRL_Español_Mar_23.pdf\n",
      "Embeddings created\n",
      "\n",
      "Processing file: data/Reporte_Definitivo_BMV_XBRL_Español_Jun_23.pdf\n",
      "Extracting text from file: data/Reporte_Definitivo_BMV_XBRL_Español_Jun_23.pdf\n",
      "Splitting docs for data/Reporte_Definitivo_BMV_XBRL_Español_Jun_23.pdf\n",
      "Creating embeddings for docs in data/Reporte_Definitivo_BMV_XBRL_Español_Jun_23.pdf\n",
      "Embeddings created\n",
      "\n",
      "Processing file: data/Reporte_Definitivo_BMV_XBRL_Español_Sep_23.pdf\n",
      "Extracting text from file: data/Reporte_Definitivo_BMV_XBRL_Español_Sep_23.pdf\n",
      "Splitting docs for data/Reporte_Definitivo_BMV_XBRL_Español_Sep_23.pdf\n",
      "Creating embeddings for docs in data/Reporte_Definitivo_BMV_XBRL_Español_Sep_23.pdf\n",
      "Embeddings created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para cada PDF dentro del directorio\n",
    "# for file in os.listdir(\"data\"):\n",
    "for file in glob.glob(\"data/*.pdf\"):\n",
    "# Crear una conexión con el PDF\n",
    "    print(f\"Processing file: {file}\")\n",
    "    loader = PyPDFLoader(f\"{file}\")\n",
    "    \n",
    "    # Paso 1: Extraer el texto del PDF\n",
    "    print(f\"Extracting text from file: {file}\")\n",
    "    pdf_data = loader.load()\n",
    "    \n",
    "    # Paso 2: Dividir el contenido del PDF en documentos\n",
    "    print(f\"Splitting docs for {file}\")\n",
    "    docs = splitter.split_documents(pdf_data)\n",
    "    \n",
    "    # Paso 3: Crear los embeddings de los documentos usando el modelo y almacenarlos en ChromaDB\n",
    "    print(f\"Creating embeddings for docs in {file}\")\n",
    "    docstorage = Chroma.from_documents(docs, embedding_model)\n",
    "\n",
    "    print(\"Embeddings created\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4e90a",
   "metadata": {},
   "source": [
    "## Realizar consultas sin formato\n",
    "\n",
    "Una vez almacenados los embeddings en la base de datos vectorias, podemos usarla para construir un RAG (básico sin formato de salida) para obtener en base al contexto de los archivos PDF que extraímos.\n",
    "\n",
    "Usamos la función `RetrievalQAWithSourcesChain` para obtener una respuesta junto con su metadata, que incluye la fuente de donde estos datos provinieron. Especialmente útil para identificar si la respuesta generada por el modelo ha sido una alucinación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcff12e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning references to RAG data sources\n"
     ]
    }
   ],
   "source": [
    "# Retornar las referencias al RAG desde la base de datos vectorial de ChormaDB\n",
    "# para generar una interfaz de comunicacion entre el modelo de IA y la base de datos vectorial para su consumo\n",
    "print(f\"Returning references to RAG data sources\")\n",
    "rag = RetrievalQAWithSourcesChain.from_chain_type( \n",
    "    llm = model, # Usar el modelo GPT\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = docstorage.as_retriever() # Usar el contenido de la base de datos\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec577ce8",
   "metadata": {},
   "source": [
    "Para probar este modelo primitivo, podemos usar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "985c2bec-fdf7-4b3f-a0f0-146eccd2fdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '¿Cuáles son las instituciones bancarias en las que Grupo Bimbo tiene un endeudamiento?',\n",
       " 'answer': 'Grupo Bimbo tiene un endeudamiento con las siguientes instituciones bancarias: BBVA Bancomer S.A., Bank of America N.A., Citibank N.A., Coöperatieve Rabobank U.A., New York HSBC México S.A., ING Bank N.V., JP Morgan Chase Bank N.A., Mizuho Bank, Ltd, Morgan Stanley Bank, N.A., MUFG Bank, Ltd. y Banco Santander S.A.\\n',\n",
       " 'sources': 'data/Reporte_Definitivo_BMV_XBRL_Español_Mar_23.pdf, data/Reporte_Definitivo_BMV_XBRL_Español_Sep_23.pdf'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cuáles son las instituciones bancarias en las que Grupo Bimbo tiene un endeudamiento?\"\n",
    "rag.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad7dd23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '¿Cuáles son los puntos principales de los papers?',\n",
       " 'answer': 'Los puntos principales de los papers son:\\n1. La finalidad primordial es lograr una posición neutral y equilibrada con relación a la exposición al riesgo de una cierta variable financiera.\\n2. Las estrategias de cobertura son valuadas y monitoreadas de manera formal y continua.\\n3. Las operaciones con instrumentos financieros derivados relacionados a materias primas son principalmente celebradas en los mercados reconocidos como el Minneapolis Grain Exchange (MGE), Kansas City Board of Trade (KCBOT), Chicago Board of Trade (CBOT), New York Mercantile Exchange (NYMEX) y Mercado de Término de Buenos Aires (MATba).\\n4. También se han realizado operaciones bilaterales ligadas a la cobertura de materias primas.\\n',\n",
       " 'sources': 'data/Reporte_Definitivo_BMV_XBRL_Español_Jun_23.pdf, data/Reporte_Definitivo_BMV_XBRL_Español_Mar_23.pdf, data/Reporte_Definitivo_BMV_XBRL_Español_Sep_23.pdf'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cuáles son los puntos principales de los papers?\"\n",
    "rag.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92cd05ee-c7a4-4030-955e-7dca09d23444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnnovenGPTTurbo:  Grupo Bimbo tiene un endeudamiento con las siguientes instituciones bancarias: BBVA Bancomer S.A., Bank of America N.A., Citibank N.A., Coöperatieve Rabobank U.A., New York HSBC México S.A., ING Bank N.V., JP Morgan Chase Bank N.A., Mizuho Bank, Ltd, Morgan Stanley Bank, N.A., MUFG Bank, Ltd. y Banco Santander S.A.\n",
      "\n",
      "\n",
      "Sources:  data/Reporte_Definitivo_BMV_XBRL_Español_Mar_23.pdf, data/Reporte_Definitivo_BMV_XBRL_Español_Sep_23.pdf\n",
      "\n",
      "ChromaDB similarity:\n",
      " BIMBO Consolidado\n",
      "Clave de Cotización:       BIMBO Trimestre:      1     Año:    2023\n",
      "69 de 172El 15 de marzo de 2023, la Compañía \n",
      "renovó su línea de crédito revolvente \n",
      "comprometida, sindicada y multimoneda, \n",
      "la cual está vinculada a la \n",
      "sustentabilidad. Las instituciones \n",
      "financieras que participan en esta \n",
      "línea son BBVA Bancomer S.A., Bank of \n",
      "America N.A., Citibank N.A., \n",
      "Coöperatieve Rabobank U.A., New York \n",
      "HSBC México S.A., ING Bank N.V., JP \n",
      "Morgan Chase Bank N.A., Mizuho Bank, \n",
      "Ltd, Morgan Stanley Bank, N.A., MUFG \n",
      "Bank, Ltd. y Banco Santander S.A. El \n",
      "nuevo monto total comprometido es de \n",
      "1,931 millones de dólares \n",
      "estadounidenses dividido en dos tramos \n",
      "con vencimiento de 875 millones el 14 \n",
      "de septiembre del 2026 (Tramo A) y \n",
      "1,056 millones  el 15 de marzo de 2028 \n",
      "(Tramo B). Las tasas de interés \n",
      "aplicables para el Tramo A son de SOFR \n",
      "más 1.05% para las disposiciones  en \n",
      "dólares estadounidenses, CDOR más \n",
      "0.95% en dólares canadienses, TIIE más \n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"¿Cuáles son las instituciones bancarias en las que Grupo Bimbo tiene un endeudamiento?\"\n",
    "matching = docstorage.similarity_search(query)\n",
    "answer = rag.invoke(query)\n",
    "print(\"EnnovenGPTTurbo: \", answer[\"answer\"], end = \"\\n\\n\")\n",
    "print(\"Sources: \", answer[\"sources\"], end = \"\\n\\n\")\n",
    "print(\"ChromaDB similarity:\\n\", matching[0].page_content, end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfbea5a",
   "metadata": {},
   "source": [
    "## Utilizar la AI y la base de datos vectorial para realizar consultas\n",
    "\n",
    "Para realizar las consultas, se pueden configurar los prompts para que aporten el contexto directo de la base de datos vectorial, así como una plantilla de la respuesta esperada para el usuario.\n",
    "\n",
    "Para ello, tambien estamos usando LCEL, que es una forma de encadenamiento de ordenes usando el pipe operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55f6b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un template para la IA\n",
    "template = \"\"\"Responde la siguiente pregunta usando el contexto: {context}. Pregunta: {question}\"\"\"\n",
    "\n",
    "# Creamos el prompt \n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "# Creamos una cadena y la ejecutamos\n",
    "chain = (\n",
    "    {\"context\" : docstorage.as_retriever(), \"question\" : RunnablePassthrough()} \n",
    "    | prompt | model\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b5edc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Las instituciones bancarias en las que Grupo Bimbo tiene un endeudamiento son BBVA Bancomer S.A., Bank of America N.A., Citibank N.A., Coöperatieve Rabobank U.A., New York HSBC México S.A., ING Bank N.V., JP Morgan Chase Bank N.A., Mizuho Bank, Ltd, Morgan Stanley Bank, N.A., MUFG Bank, Ltd. y Banco Santander S.A.')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"¿Cuáles son las instituciones bancarias en las que Grupo Bimbo tiene un endeudamiento?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
